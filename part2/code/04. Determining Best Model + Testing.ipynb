{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2347a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b2b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pickles = \"Models/\"\n",
    "\n",
    "list_pickles = [\n",
    "    #\"df_models_gbc.pickle\",\n",
    "    \"df_models_knnc.pickle\",\n",
    "    \"df_models_lrc.pickle\",\n",
    "    \"df_models_mnbc.pickle\",\n",
    "    \"df_models_rfc.pickle\",\n",
    "    \"df_models_svc.pickle\"\n",
    "]\n",
    "\n",
    "df_summary = pd.DataFrame()\n",
    "\n",
    "for pickle_ in list_pickles:\n",
    "    \n",
    "    path = path_pickles + pickle_\n",
    "    \n",
    "    with open(path, 'rb') as data:\n",
    "        df = pickle.load(data)\n",
    "\n",
    "    df_summary = df_summary.append(df)\n",
    "\n",
    "df_summary = df_summary.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe33a1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.811061</td>\n",
       "      <td>0.767616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial Naïve Bayes</td>\n",
       "      <td>0.763694</td>\n",
       "      <td>0.755622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.901032</td>\n",
       "      <td>0.752624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.737761</td>\n",
       "      <td>0.725637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.951839</td>\n",
       "      <td>0.643178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Training Set Accuracy  Test Set Accuracy\n",
       "1      Logistic Regression               0.811061           0.767616\n",
       "2  Multinomial Naïve Bayes               0.763694           0.755622\n",
       "3            Random Forest               0.901032           0.752624\n",
       "4                      SVM               0.737761           0.725637\n",
       "0                      KNN               0.951839           0.643178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.sort_values('Test Set Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c7f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import punkt\n",
    "from nltk.corpus.reader import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ecb4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = \"Models/\"\n",
    "\n",
    "# SVM\n",
    "path_svm = path_models + 'best_svc.pickle'\n",
    "with open(path_svm, 'rb') as data:\n",
    "    svc_model = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42a4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tfidf = \"Pickles/tfidf.pickle\"\n",
    "with open(path_tfidf, 'rb') as data:\n",
    "    tfidf = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04bbf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;\")\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "def create_features_from_text(text):\n",
    "    \n",
    "    # Dataframe creation\n",
    "    lemmatized_text_list = []\n",
    "    df = pd.DataFrame(columns=['Content'])\n",
    "    df.loc[0] = text\n",
    "    df['Content_Parsed_1'] = df['Content'].str.replace(\"\\r\", \" \")\n",
    "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"\\n\", \" \")\n",
    "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace(\"    \", \" \")\n",
    "    df['Content_Parsed_1'] = df['Content_Parsed_1'].str.replace('\"', '')\n",
    "    df['Content_Parsed_2'] = df['Content_Parsed_1'].str.lower()\n",
    "    df['Content_Parsed_3'] = df['Content_Parsed_2']\n",
    "    for punct_sign in punctuation_signs:\n",
    "        df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n",
    "    df['Content_Parsed_4'] = df['Content_Parsed_3'].str.replace(\"'s\", \"\")\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_list = []\n",
    "    text = df.loc[0]['Content_Parsed_4']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "    lemmatized_text = \" \".join(lemmatized_list)    \n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "    df['Content_Parsed_5'] = lemmatized_text_list\n",
    "    df['Content_Parsed_6'] = df['Content_Parsed_5']\n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n",
    "    df = df['Content_Parsed_6']\n",
    "    \n",
    "    \n",
    "    # TF-IDF\n",
    "    features = tfidf.transform(df).toarray()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f543a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_name(category_id):\n",
    "    for category, id_ in category_codes.items():    \n",
    "        if id_ == category_id:\n",
    "            return category\n",
    "category_codes = {\n",
    "    'Law': 0,\n",
    "    'Historical': 1,\n",
    "    'Prophets': 2,\n",
    "    'Gospel': 3,\n",
    "    'Letters': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d621f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_text(text):\n",
    "    \n",
    "    # Predict using the input model\n",
    "    prediction_svc = svc_model.predict(create_features_from_text(text))[0]\n",
    "    prediction_svc_proba = svc_model.predict_proba(create_features_from_text(text))[0]\n",
    "    \n",
    "    # Return result\n",
    "    category_svc = get_category_name(prediction_svc)\n",
    "    \n",
    "    print(\"The predicted category using the SVM model is %s.\" %(category_svc) )\n",
    "    print(\"The conditional probability is: %a\" %(prediction_svc_proba.max()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "701dff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "“We are all like fireworks: We climb, we shine and always go our separate ways and become further apart” \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6c882d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted category using the SVM model is Prophets.\n",
      "The conditional probability is: 71.44567268489091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sf/b607g6w95rq9hv8v55xc25km0000gn/T/ipykernel_33960/3091447222.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n",
      "/var/folders/sf/b607g6w95rq9hv8v55xc25km0000gn/T/ipykernel_33960/3091447222.py:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n",
      "/var/folders/sf/b607g6w95rq9hv8v55xc25km0000gn/T/ipykernel_33960/3091447222.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Content_Parsed_3'] = df['Content_Parsed_3'].str.replace(punct_sign, '')\n",
      "/var/folders/sf/b607g6w95rq9hv8v55xc25km0000gn/T/ipykernel_33960/3091447222.py:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Content_Parsed_6'] = df['Content_Parsed_6'].str.replace(regex_stopword, '')\n"
     ]
    }
   ],
   "source": [
    "predict_from_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
